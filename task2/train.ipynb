{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "threaded-concept",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as nnfunc\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "from torch.optim import SGD\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import random_split, Subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "expected-component",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['not_wearing','wearing_eyeglasses','wearing_hat']\n",
    "\n",
    "transformer = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "#     transforms.Resize((32,32)),\n",
    "    transforms.Normalize([0.5,0.5,0.5],\n",
    "                        [0.5,0.5,0.5])\n",
    "])\n",
    "\n",
    "train_path = 'data_wearing/train'\n",
    "test_path = 'data_wearing/test'\n",
    "\n",
    "train_data = torchvision.datasets.ImageFolder(train_path, transform=transformer)\n",
    "\n",
    "train_ratio = 0.8\n",
    "train_size = int(train_ratio * len(train_data))\n",
    "val_size = len(train_data) - train_size\n",
    "train_set, val_set = random_split(train_data, [train_size, val_size])\n",
    "\n",
    "trainloader = DataLoader(\n",
    "    train_set,\n",
    "    batch_size = 64,\n",
    "    shuffle = True\n",
    ")\n",
    "\n",
    "valloader = DataLoader(\n",
    "    val_set,\n",
    "    batch_size = 64,\n",
    "    shuffle = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "prescribed-bargain",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResBlock(in_channels, out_channels, pool=False):\n",
    "    layers = []\n",
    "    layers.append(nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1))\n",
    "    layers.append(nn.BatchNorm2d(out_channels))\n",
    "    layers.append(nn.ReLU(inplace=True))\n",
    "    if pool: \n",
    "        layers.append(nn.MaxPool2d(2))\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "class ResNet9(nn.Module):\n",
    "    def __init__(self, in_channels, num_classes):\n",
    "        super().__init__()\n",
    "        self.conv1 = ResBlock(in_channels, 64)\n",
    "        self.conv2 = ResBlock(64, 128, pool=True)\n",
    "        self.res1 = nn.Sequential(ResBlock(128, 128), ResBlock(128, 128))\n",
    "        self.conv3 = ResBlock(128, 256, pool=True)\n",
    "        self.conv4 = ResBlock(256, 512, pool=True)\n",
    "        self.res2 = nn.Sequential(ResBlock(512, 512), ResBlock(512, 512))\n",
    "        self.fc = nn.Sequential(nn.MaxPool2d(4), \n",
    "                                        nn.Flatten(), \n",
    "                                        nn.Dropout(0.2),\n",
    "                                        nn.Linear(512, num_classes))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.conv2(out)\n",
    "        out = self.res1(out) + out\n",
    "        out = self.conv3(out)\n",
    "        out = self.conv4(out)\n",
    "        out = self.res2(out) + out\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "civic-principle",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Train_accuracy 0.6874003189792663\n",
      "Train Loss 0.7214318513870239\n",
      "Val Accuracy 0.5725677830940988\n",
      "Best Val Accuracy 0.5725677830940988\n",
      "Epoch 1\n",
      "Train_accuracy 0.8863636363636364\n",
      "Train Loss 0.30987101793289185\n",
      "Val Accuracy 0.7033492822966507\n",
      "Best Val Accuracy 0.7033492822966507\n",
      "Epoch 2\n",
      "Train_accuracy 0.9577352472089314\n",
      "Train Loss 0.12823641300201416\n",
      "Val Accuracy 0.8532695374800638\n",
      "Best Val Accuracy 0.8532695374800638\n",
      "Epoch 3\n",
      "Train_accuracy 0.9772727272727273\n",
      "Train Loss 0.06261049956083298\n",
      "Val Accuracy 0.8373205741626795\n",
      "Epoch 4\n",
      "Train_accuracy 0.9856459330143541\n",
      "Train Loss 0.03785247355699539\n",
      "Val Accuracy 0.7751196172248804\n",
      "Epoch 5\n",
      "Train_accuracy 0.9924242424242424\n",
      "Train Loss 0.03324383124709129\n",
      "Val Accuracy 0.7990430622009569\n",
      "Epoch 6\n",
      "Train_accuracy 0.9904306220095693\n",
      "Train Loss 0.027133379131555557\n",
      "Val Accuracy 0.7655502392344498\n",
      "Epoch 7\n",
      "Train_accuracy 0.9952153110047847\n",
      "Train Loss 0.017611326649785042\n",
      "Val Accuracy 0.8229665071770335\n",
      "Epoch 8\n",
      "Train_accuracy 0.9860446570972887\n",
      "Train Loss 0.04067786782979965\n",
      "Val Accuracy 0.7543859649122807\n",
      "Epoch 9\n",
      "Train_accuracy 0.9772727272727273\n",
      "Train Loss 0.07184842973947525\n",
      "Val Accuracy 0.8054226475279107\n",
      "Epoch 10\n",
      "Train_accuracy 0.9629186602870813\n",
      "Train Loss 0.09754885733127594\n",
      "Val Accuracy 0.8022328548644339\n",
      "Epoch 11\n",
      "Train_accuracy 0.9740829346092504\n",
      "Train Loss 0.07227127254009247\n",
      "Val Accuracy 0.8086124401913876\n",
      "Epoch 12\n",
      "Train_accuracy 0.9912280701754386\n",
      "Train Loss 0.023502830415964127\n",
      "Val Accuracy 0.8421052631578947\n",
      "Epoch 13\n",
      "Train_accuracy 0.9976076555023924\n",
      "Train Loss 0.010511756874620914\n",
      "Val Accuracy 0.8389154704944178\n",
      "Epoch 14\n",
      "Train_accuracy 0.9992025518341308\n",
      "Train Loss 0.0060887630097568035\n",
      "Val Accuracy 0.861244019138756\n",
      "Best Val Accuracy 0.861244019138756\n",
      "Epoch 15\n",
      "Train_accuracy 0.9988038277511961\n",
      "Train Loss 0.005654219537973404\n",
      "Val Accuracy 0.8708133971291866\n",
      "Best Val Accuracy 0.8708133971291866\n",
      "Epoch 16\n",
      "Train_accuracy 0.9988038277511961\n",
      "Train Loss 0.005335377529263496\n",
      "Val Accuracy 0.8500797448165869\n",
      "Epoch 17\n",
      "Train_accuracy 1.0\n",
      "Train Loss 0.0024871230125427246\n",
      "Val Accuracy 0.8628389154704944\n",
      "Epoch 18\n",
      "Train_accuracy 1.0\n",
      "Train Loss 0.0009528013761155307\n",
      "Val Accuracy 0.8580542264752791\n",
      "Epoch 19\n",
      "Train_accuracy 1.0\n",
      "Train Loss 0.0007668860489502549\n",
      "Val Accuracy 0.8724082934609251\n",
      "Best Val Accuracy 0.8724082934609251\n",
      "Epoch 20\n",
      "Train_accuracy 1.0\n",
      "Train Loss 0.0005149062490090728\n",
      "Val Accuracy 0.8724082934609251\n",
      "Epoch 21\n",
      "Train_accuracy 1.0\n",
      "Train Loss 0.000260430941125378\n",
      "Val Accuracy 0.8660287081339713\n",
      "Epoch 22\n",
      "Train_accuracy 1.0\n",
      "Train Loss 0.0002943167637567967\n",
      "Val Accuracy 0.8660287081339713\n",
      "Epoch 23\n",
      "Train_accuracy 1.0\n",
      "Train Loss 0.00022260224795900285\n",
      "Val Accuracy 0.8708133971291866\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# model = ResNet9(3, 3)\n",
    "\n",
    "# ResNet\n",
    "model = torchvision.models.resnet18(pretrained=False)\n",
    "inchannel = model.fc.in_features\n",
    "model.fc = nn.Linear(inchannel, 3)\n",
    "\n",
    "# Continue training\n",
    "# best_model = torch.load('model/task2.model')\n",
    "# model.load_state_dict(best_model, strict=False)\n",
    "\n",
    "model.to(device)\n",
    "torch.save(model.state_dict(), 'model/task2-resnet18-adam-30.model')\n",
    "\n",
    "lr = 0.01\n",
    "weight_decay = 1e-4\n",
    "num_epoches = 30\n",
    "grad_clip = 0.1\n",
    "\n",
    "train_count = len(train_set)\n",
    "val_count = len(val_set)\n",
    "\n",
    "optimizer = Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "# optimizer = Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "scheduler = lr_scheduler.OneCycleLR(optimizer, lr, epochs=num_epoches, steps_per_epoch=train_count)\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "best_accuracy = 0.0\n",
    "\n",
    "hist = []\n",
    "\n",
    "# for epoch in range(30,45):\n",
    "for epoch in range(num_epoches):\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    train_accuracy = 0.0\n",
    "    train_loss = 0.0\n",
    "    for i, (images, labels) in enumerate(trainloader):\n",
    "        if torch.cuda.is_available():\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = loss_function(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # gradient clipping\n",
    "        nn.utils.clip_grad_value_(model.parameters(), grad_clip)\n",
    "\n",
    "        train_loss += loss.cpu().data * images.size(0)\n",
    "        _, prediction = torch.max(outputs.data,1)\n",
    "        train_accuracy += int(torch.sum(prediction == labels.data))\n",
    "    \n",
    "    train_accuracy = train_accuracy / train_count\n",
    "    train_loss = train_loss/train_count\n",
    "    \n",
    "    model.eval()\n",
    "    val_accuracy = 0.0\n",
    "    with torch.no_grad():\n",
    "        for i, (images, labels) in enumerate(valloader):\n",
    "            if torch.cuda.is_available():\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _,prediction = torch.max(outputs.data,1)\n",
    "            val_accuracy += int(torch.sum(prediction==labels.data))\n",
    "\n",
    "        val_accuracy = val_accuracy / val_count\n",
    "        \n",
    "        print(f\"Epoch {epoch}\")\n",
    "        print(f\"Train_accuracy {train_accuracy}\")\n",
    "        print(f\"Train Loss {train_loss}\")\n",
    "        print(f\"Val Accuracy {val_accuracy}\")\n",
    "        \n",
    "        hist.append({ \n",
    "            'epoch':epoch,\n",
    "            'train_accuracy':train_accuracy,\n",
    "            'val_accuracy':val_accuracy,\n",
    "            'best_accuracy':best_accuracy,\n",
    "            'train_loss':train_loss\n",
    "        })\n",
    "        \n",
    "        if val_accuracy > best_accuracy:\n",
    "            print(f\"Best Val Accuracy {val_accuracy}\")\n",
    "            torch.save(model.state_dict(), 'model/task2-resnet18-adam-30.model')\n",
    "            best_accuracy = val_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liable-savings",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x = np.arange(1, len(hist)+1)\n",
    "\n",
    "fig, ax = plt.subplots()  # Create a figure and an axes.\n",
    "train_accuracy = list(map(lambda x: x['train_accuracy'], hist))\n",
    "val_accuracy = list(map(lambda x: x['val_accuracy'], hist))\n",
    "\n",
    "train_loss = list(map(lambda x: x['train_loss'], hist))\n",
    "train_loss = train_loss / np.linalg.norm(train_loss)\n",
    "\n",
    "plt.plot(x, train_accuracy, label='train accuracy')  # Plot some data on the axes.\n",
    "plt.plot(x, val_accuracy, label='val accuracy')  # Plot more data on the axes...\n",
    "plt.plot(x, train_loss, label='train loss')  # ... and some more.\n",
    "plt.xlabel('#Epochs')  # Add an x-label to the axes.\n",
    "plt.ylabel('Accuracy/Normalized Loss')  # Add a y-label to the axes.\n",
    "plt.title(\"task2-resnet18-adam-30\")  # Add a title to the axes.\n",
    "plt.legend()  # Add a legend.\n",
    "\n",
    "plt.annotate(f'{np.max(train_accuracy)}', xy=(np.argmax(train_accuracy) + 1, np.max(train_accuracy)), arrowprops=dict(facecolor='black', shrink=0.05))\n",
    "plt.annotate(f'{np.max(val_accuracy)}', xy=(np.argmax(val_accuracy) + 1, np.max(val_accuracy)), arrowprops=dict(facecolor='black', shrink=0.05))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
